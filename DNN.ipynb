{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from MyDatasetLoader import MyDatasetLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reduce_dim_pca(dataset,reduce_dim_to):\n",
    "    pca = PCA(n_components=reduce_dim_to)\n",
    "    x= pca.fit_transform(dataset[0].x)\n",
    "   \n",
    "    dataset.data.x =torch.tensor(x,dtype=torch.float32)\n",
    "    return \n",
    "dataset=MyDatasetLoader(root='./cora')\n",
    "#reduce_dim_pca(dataset,300)\n",
    "\n",
    "train_x= dataset[0].x[dataset[0].train_mask].to('cpu').numpy()\n",
    "train_y= dataset[0].y[dataset[0].train_mask].to('cpu').numpy()\n",
    "test_x = dataset[0].x[dataset[0].test_mask].to('cpu').numpy()\n",
    "test_y = dataset[0].y[dataset[0].test_mask].to('cpu').numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n",
      "2708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "train_x= dataset[0].x[dataset[0].train_mask].to('cpu').numpy()\n",
    "train_y= dataset[0].y[dataset[0].train_mask].to('cpu').numpy()\n",
    "test_x = dataset[0].x[dataset[0].test_mask].to('cpu').numpy()\n",
    "test_y = dataset[0].y[dataset[0].test_mask].to('cpu').numpy()\n",
    "\n",
    "full_train_x=dataset[0].x.to('cpu').numpy()\n",
    "full_train_y=dataset[0].y.to('cpu').numpy()\n",
    "\n",
    "\n",
    "hot_full_train_y= ohe.fit_transform(full_train_y.reshape(-1, 1)).toarray()\n",
    "print(len(hot_full_train_y))\n",
    "print(len(full_train_x))\n",
    "\n",
    "\n",
    "val_x = dataset[0].x[dataset[0].val_mask].to('cpu').numpy()\n",
    "val_y = dataset[0].y[dataset[0].val_mask].to('cpu').numpy()\n",
    "hot_train_y = ohe.fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "hot_test_y=  ohe.fit_transform(test_y.reshape(-1, 1)).toarray()\n",
    "hot_val_y=  ohe.fit_transform(val_y.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "def convert_from_one_hot(pred_one_hot):\n",
    "    pred = list()\n",
    "    for i in range(len(pred_one_hot)):\n",
    "        pred.append(np.argmax(pred_one_hot[i]))\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 0s 931us/step - loss: 1.8754 - accuracy: 0.2714\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 0s 931us/step - loss: 1.7507 - accuracy: 0.3138\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 0s 922us/step - loss: 1.6313 - accuracy: 0.3194\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 0s 902us/step - loss: 1.4726 - accuracy: 0.4043\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 0s 902us/step - loss: 1.2946 - accuracy: 0.5298\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 0s 971us/step - loss: 1.1181 - accuracy: 0.6246\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 0s 931us/step - loss: 0.8677 - accuracy: 0.6972\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.7566 - accuracy: 0.7262\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 0s 912us/step - loss: 0.6293 - accuracy: 0.7766\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 0s 892us/step - loss: 0.5592 - accuracy: 0.8037\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.4498 - accuracy: 0.8462\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 0s 922us/step - loss: 0.4256 - accuracy: 0.8523\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.4143 - accuracy: 0.8554\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.3181 - accuracy: 0.8960\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 0s 961us/step - loss: 0.2716 - accuracy: 0.9163\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 0s 922us/step - loss: 0.2446 - accuracy: 0.9249\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 0s 853us/step - loss: 0.2652 - accuracy: 0.9200\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 0s 892us/step - loss: 0.2315 - accuracy: 0.9280\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.2269 - accuracy: 0.9268\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 0s 873us/step - loss: 0.1935 - accuracy: 0.9458\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1755 - accuracy: 0.9483\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1863 - accuracy: 0.9440\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1544 - accuracy: 0.9557\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 0s 892us/step - loss: 0.1742 - accuracy: 0.9452\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 0s 862us/step - loss: 0.1631 - accuracy: 0.9526\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.1576 - accuracy: 0.9545\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 0s 911us/step - loss: 0.1366 - accuracy: 0.9606\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.1498 - accuracy: 0.9582\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 0s 902us/step - loss: 0.1286 - accuracy: 0.9668\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 0s 951us/step - loss: 0.1226 - accuracy: 0.9618\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.1329 - accuracy: 0.9606\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1067 - accuracy: 0.9674\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.0987 - accuracy: 0.9760\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 0s 892us/step - loss: 0.1249 - accuracy: 0.9662\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.1177 - accuracy: 0.9649\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1230 - accuracy: 0.9618\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 0s 902us/step - loss: 0.1166 - accuracy: 0.9662\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 0s 873us/step - loss: 0.1037 - accuracy: 0.9735\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.1466 - accuracy: 0.9569\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.0957 - accuracy: 0.9742\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.1094 - accuracy: 0.9649\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 0s 873us/step - loss: 0.0973 - accuracy: 0.9723\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.0874 - accuracy: 0.9748\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 0s 912us/step - loss: 0.0895 - accuracy: 0.9742\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 0s 883us/step - loss: 0.0986 - accuracy: 0.9698\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 0s 873us/step - loss: 0.0813 - accuracy: 0.9791\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 0s 853us/step - loss: 0.0999 - accuracy: 0.9723\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 0s 863us/step - loss: 0.0819 - accuracy: 0.9785\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 0s 882us/step - loss: 0.0782 - accuracy: 0.9797\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 0s 873us/step - loss: 0.0770 - accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=len(train_x[0]), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_x, hot_train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16236162361623616\n",
      "f1: 0.039909297052154194\n",
      "confusion matrix:\n",
      " [[  0   0   0   0   0 235   0]\n",
      " [  0   0   0   0   0  62   0]\n",
      " [  0   0   0   0   0  60   0]\n",
      " [  0   0   0   0   0 120   0]\n",
      " [  0   0   0   0   0 114   0]\n",
      " [  0   0   0   0   0 132   0]\n",
      " [  0   0   0   0   0  90   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(test_x)\n",
    "\n",
    "y_pred=convert_from_one_hot(pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(test_y, y_pred,average='macro'))\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981538461538462\n",
      "f1: 0.9986674966941893\n",
      "confusion matrix:\n",
      " [[506   0   0   1   0   0   0]\n",
      " [  0 107   0   0   0   0   0]\n",
      " [  0   0 130   0   0   0   0]\n",
      " [  1   0   0 263   0   0   0]\n",
      " [  1   0   0   0 193   0   0]\n",
      " [  0   0   0   0   0 248   0]\n",
      " [  0   0   0   0   0   0 175]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(train_x)\n",
    "\n",
    "y_pred=convert_from_one_hot(pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(train_y, y_pred,average='macro'))\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(train_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14074074074074075\n",
      "f1: 0.03525046382189239\n",
      "confusion matrix:\n",
      " [[ 0  0  0  0  0 76  0]\n",
      " [ 0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0 42  0]\n",
      " [ 0  0  0  0  0 43  0]\n",
      " [ 0  0  0  0  0 38  0]\n",
      " [ 0  0  0  0  0 33  0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(val_x)\n",
    "\n",
    "y_pred=convert_from_one_hot(pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(val_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(val_y, y_pred,average='macro'))\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(val_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 0 ...\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.9365 - accuracy: 0.2059\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.8712 - accuracy: 0.3158\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7634 - accuracy: 0.3186\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.6374 - accuracy: 0.3176\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4554 - accuracy: 0.4183\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.2301 - accuracy: 0.5531\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9670 - accuracy: 0.6676\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7490 - accuracy: 0.7682\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.8393\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8790\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9243\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9455\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9658\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9649\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9834\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9797\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9834\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9806\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9908\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9926\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9945\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9926\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9935\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9982\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9954\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9963\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9982\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9991\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9972\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9954\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9954\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9982\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9982\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9991\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9982\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9991\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9991\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9991\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9991\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9991\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9991\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Score for fold 0: loss of 1.4880121946334839; accuracy of 74.90774989128113%\n",
      "Accuracy: 0.7490774907749077\n",
      "f1: 0.7071001569209604\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [813, 542]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32560/1960319835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"f1:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"confusion matrix:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tesiNew\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tesiNew\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tesiNew\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [813, 542]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "models=[]\n",
    "fold_no=0\n",
    "\n",
    "#train_x=full_train_x\n",
    "#train_y=full_train_y\n",
    "#hot_train_y=hot_full_train_y\n",
    "\n",
    "for train, test in kfold.split(train_x, hot_train_y):\n",
    "   \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=len(train_x[0]), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = model.fit(train_x[train], train_y[train],\n",
    "              batch_size=100,\n",
    "              epochs=50,\n",
    "             )\n",
    "    scores = model.evaluate(train_x[test], train_y[test], verbose=0)\n",
    "    models.append(model)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    pred=model.predict(train_x[test])\n",
    "    y_pred=convert_from_one_hot(pred)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score( train_y[test], y_pred))\n",
    "    print(\"f1:\",metrics.f1_score( train_y[test], y_pred,average='macro'))\n",
    "    print(\"confusion matrix:\\n\",metrics.confusion_matrix(train_y[test], y_pred))\n",
    "    \n",
    "    \n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.344421625137329 - Accuracy: 77.12177038192749%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.6538147926330566 - Accuracy: 71.95571660995483%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.78190016746521 - Accuracy: 73.3826220035553%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 74.15336966514587 (+- 2.1783123225888636)\n",
      "> Loss: 1.5933788617451985\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------fold number 0------\n",
      "Accuracy: 0.2890528905289053\n",
      "f1: 0.06406761177753544\n",
      "confusion matrix:\n",
      " [[235   0   0   0   0   0   0]\n",
      " [ 62   0   0   0   0   0   0]\n",
      " [ 60   0   0   0   0   0   0]\n",
      " [120   0   0   0   0   0   0]\n",
      " [114   0   0   0   0   0   0]\n",
      " [132   0   0   0   0   0   0]\n",
      " [ 90   0   0   0   0   0   0]]\n",
      "-------fold number 1------\n",
      "Accuracy: 0.2890528905289053\n",
      "f1: 0.06406761177753544\n",
      "confusion matrix:\n",
      " [[235   0   0   0   0   0   0]\n",
      " [ 62   0   0   0   0   0   0]\n",
      " [ 60   0   0   0   0   0   0]\n",
      " [120   0   0   0   0   0   0]\n",
      " [114   0   0   0   0   0   0]\n",
      " [132   0   0   0   0   0   0]\n",
      " [ 90   0   0   0   0   0   0]]\n",
      "-------fold number 2------\n",
      "Accuracy: 0.2890528905289053\n",
      "f1: 0.06406761177753544\n",
      "confusion matrix:\n",
      " [[235   0   0   0   0   0   0]\n",
      " [ 62   0   0   0   0   0   0]\n",
      " [ 60   0   0   0   0   0   0]\n",
      " [120   0   0   0   0   0   0]\n",
      " [114   0   0   0   0   0   0]\n",
      " [132   0   0   0   0   0   0]\n",
      " [ 90   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model,fold in zip(models,range(0,len(models))):\n",
    "    print(f'-------fold number {fold}------')\n",
    "    pred=model.predict(test_x)\n",
    "    y_pred=convert_from_one_hot(pred)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "    print(\"f1:\",metrics.f1_score(test_y, y_pred,average='macro'))\n",
    "    print(\"confusion matrix:\\n\",metrics.confusion_matrix(test_y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b1ab523bc40703e7c4f09cc002dd307caa8b861633741d7ebd49339b733c3d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tesiNew': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
