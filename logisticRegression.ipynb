{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "from MyDatasetLoader import MyDatasetLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "\n",
    "\n",
    "def reduce_dim_pca(dataset,reduce_dim_to):\n",
    "    pca = PCA(n_components=reduce_dim_to)\n",
    "    x= pca.fit_transform(dataset[0].x)\n",
    "   \n",
    "    dataset.data.x =torch.tensor(x,dtype=torch.float32)\n",
    "    return \n",
    "dataset=MyDatasetLoader(root='./cora')\n",
    "reduce_dim_pca(dataset,100)\n",
    "\n",
    "train_x= dataset[0].x[dataset[0].train_mask]\n",
    "train_y= dataset[0].y[dataset[0].train_mask]\n",
    "test_x = dataset[0].x[dataset[0].test_mask]\n",
    "test_y = dataset[0].y[dataset[0].test_mask]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2939729397293973\n",
      "f1: 0.06491037479630636\n",
      "{'Neural_Networks': 0, 'Rule_Learning': 1, 'Reinforcement_Learning': 2, 'Probabilistic_Methods': 3, 'Theory': 4, 'Genetic_Algorithms': 5, 'Case_Based': 6}\n",
      "confusion matrix:\n",
      " [[239   0   0   0   0   0   0]\n",
      " [ 69   0   0   0   0   0   0]\n",
      " [ 80   0   0   0   0   0   0]\n",
      " [132   0   0   0   0   0   0]\n",
      " [101   0   0   0   0   0   0]\n",
      " [117   0   0   0   0   0   0]\n",
      " [ 75   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=1.0)\n",
    "clf.fit(train_x,train_y)\n",
    "clf = clf.fit(train_x,train_y)\n",
    "y_pred = clf.predict(test_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(test_y, y_pred,average='macro'))\n",
    "print(dataset.data.label_map)\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8344615384615385\n",
      "f1: 0.8234760860787002\n",
      "{'Neural_Networks': 0, 'Rule_Learning': 1, 'Reinforcement_Learning': 2, 'Probabilistic_Methods': 3, 'Theory': 4, 'Genetic_Algorithms': 5, 'Case_Based': 6}\n",
      "confusion matrix:\n",
      " [[436   3   6  23  16   3   6]\n",
      " [  6  65   1   2  11   1  11]\n",
      " [  8   0 105   0   5   6   2]\n",
      " [ 33   0   1 204   5   1   3]\n",
      " [ 26   5   2   7 163   3   8]\n",
      " [ 16   2   4   3   0 227   1]\n",
      " [ 14   3   2   4  12   4 156]]\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(train_x,train_y)\n",
    "y_pred = clf.predict(train_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(train_y, y_pred,average='macro'))\n",
    "print(dataset.data.label_map)\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(train_y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b1ab523bc40703e7c4f09cc002dd307caa8b861633741d7ebd49339b733c3d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tesiNew': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
