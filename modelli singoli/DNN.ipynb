{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from MyDatasetLoader import MyDatasetLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reduce_dim_pca(dataset,reduce_dim_to):\n",
    "    pca = PCA(n_components=reduce_dim_to)\n",
    "    x= pca.fit_transform(dataset[0].x)\n",
    "   \n",
    "    dataset.data.x =torch.tensor(x,dtype=torch.float32)\n",
    "    return \n",
    "dataset=MyDatasetLoader(root='./cora')\n",
    "#reduce_dim_pca(dataset,300)\n",
    "\n",
    "train_x= dataset[0].x[dataset[0].train_mask].to('cpu').numpy()\n",
    "train_y= dataset[0].y[dataset[0].train_mask].to('cpu').numpy()\n",
    "test_x = dataset[0].x[dataset[0].test_mask].to('cpu').numpy()\n",
    "test_y = dataset[0].y[dataset[0].test_mask].to('cpu').numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "train_x= dataset[0].x[dataset[0].train_mask].to('cpu').numpy()\n",
    "train_y= dataset[0].y[dataset[0].train_mask].to('cpu').numpy()\n",
    "test_x = dataset[0].x[dataset[0].test_mask].to('cpu').numpy()\n",
    "test_y = dataset[0].y[dataset[0].test_mask].to('cpu').numpy()\n",
    "\n",
    "full_train_x=dataset[0].x.to('cpu').numpy()\n",
    "full_train_y=dataset[0].y.to('cpu').numpy()\n",
    "\n",
    "\n",
    "hot_full_train_y= ohe.fit_transform(full_train_y.reshape(-1, 1)).toarray()\n",
    "hot_train_y = ohe.fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "hot_test_y=  ohe.fit_transform(test_y.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "\n",
    "def convert_from_one_hot(pred_one_hot):\n",
    "    pred = list()\n",
    "    for i in range(len(pred_one_hot)):\n",
    "        pred.append(np.argmax(pred_one_hot[i]))\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "51/51 [==============================] - 0s 902us/step - loss: 1.8904 - accuracy: 0.2560\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 0s 902us/step - loss: 1.7693 - accuracy: 0.3089\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 0s 853us/step - loss: 1.6654 - accuracy: 0.3311\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 0s 931us/step - loss: 1.5203 - accuracy: 0.3926\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 0s 902us/step - loss: 1.3236 - accuracy: 0.5077\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 0s 941us/step - loss: 1.1577 - accuracy: 0.5828\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 0s 941us/step - loss: 0.9949 - accuracy: 0.6418\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.6702\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 0s 931us/step - loss: 0.7831 - accuracy: 0.7231\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 0s 971us/step - loss: 0.6803 - accuracy: 0.7508\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 0s 912us/step - loss: 0.5966 - accuracy: 0.7791\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 0s 922us/step - loss: 0.5861 - accuracy: 0.7858\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 0s 971us/step - loss: 0.5022 - accuracy: 0.8228\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 0s 941us/step - loss: 0.4471 - accuracy: 0.8431\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 0s 931us/step - loss: 0.4235 - accuracy: 0.8554\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 0s 902us/step - loss: 0.3755 - accuracy: 0.8695\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 0s 931us/step - loss: 0.3201 - accuracy: 0.8892\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 0s 912us/step - loss: 0.3119 - accuracy: 0.8911\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 0s 980us/step - loss: 0.3057 - accuracy: 0.8911\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 0s 922us/step - loss: 0.2729 - accuracy: 0.9120\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=len(train_x[0]), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_x, hot_train_y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7414589104339797\n",
      "f1: 0.7126828581993351\n",
      "confusion matrix:\n",
      " [[259   1  12  21  13  11   2]\n",
      " [  8  34   5   3  11   0   2]\n",
      " [ 11   1  64   7   3   6   4]\n",
      " [ 27   2   3 152   7   1   1]\n",
      " [ 26   6   3   8  81   7   8]\n",
      " [ 11   1   4   1   3 140   1]\n",
      " [  6   4   9   7   8   5  73]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(test_x)\n",
    "\n",
    "y_pred=convert_from_one_hot(pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(test_y, y_pred,average='macro'))\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981538461538462\n",
      "f1: 0.9986674966941893\n",
      "confusion matrix:\n",
      " [[506   0   0   1   0   0   0]\n",
      " [  0 107   0   0   0   0   0]\n",
      " [  0   0 130   0   0   0   0]\n",
      " [  1   0   0 263   0   0   0]\n",
      " [  1   0   0   0 193   0   0]\n",
      " [  0   0   0   0   0 248   0]\n",
      " [  0   0   0   0   0   0 175]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(train_x)\n",
    "\n",
    "y_pred=convert_from_one_hot(pred)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred))\n",
    "print(\"f1:\",metrics.f1_score(train_y, y_pred,average='macro'))\n",
    "print(\"confusion matrix:\\n\",metrics.confusion_matrix(train_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 0 ...\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.9019 - accuracy: 0.2881\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7980 - accuracy: 0.3102\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.7001 - accuracy: 0.3102\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5785 - accuracy: 0.3232\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.3947 - accuracy: 0.4349\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.1859 - accuracy: 0.6159\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.7119\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.8153\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8680\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.9104\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9280\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9483\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9612\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9769\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9852\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9797\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9852\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9926\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9917\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9861\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9908\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9917\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9945\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9972\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9954\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9954\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9945\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9972\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9982\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9972\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9991\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9991\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9982\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9982\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9982\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9991\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9991\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.9991\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9991\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9963\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9982\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9991\n",
      "Score for fold 0: loss of 1.4687252044677734; accuracy of 74.16974306106567%\n",
      "Accuracy: 0.7416974169741697\n",
      "f1: 0.7342888394150967\n",
      "confusion matrix:\n",
      " [[126   2   3  12   9   6   5]\n",
      " [  2  20   0   0   4   1   6]\n",
      " [  6   1  28   1   0   1   1]\n",
      " [ 18   0   0  58   4   4   2]\n",
      " [ 16   2   2   1  40   1   6]\n",
      " [  6   0   1   1   2  81   2]\n",
      " [  5   0   0   1   2   4  49]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9013 - accuracy: 0.2789\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8082 - accuracy: 0.3084\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7108 - accuracy: 0.3084\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.5988 - accuracy: 0.3093\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4522 - accuracy: 0.3620\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2403 - accuracy: 0.5605\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9611 - accuracy: 0.7276\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.8089\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8532\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8938\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9455\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9557\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9658\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9741\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9751\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9843\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9871\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9843\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9889\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9898\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9908\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9908\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9963\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9945\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9945\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9972\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9982\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9945\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9963\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9982\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9982\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9991\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9991\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9982\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9991\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9954\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.9991\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9972\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9991\n",
      "Score for fold 1: loss of 1.9200348854064941; accuracy of 70.47970294952393%\n",
      "Accuracy: 0.7047970479704797\n",
      "f1: 0.6614221986033655\n",
      "confusion matrix:\n",
      " [[136   1   4  14   5   4   1]\n",
      " [  3  16   3   3   8   2   6]\n",
      " [  7   1  22   1   0   4   2]\n",
      " [ 12   2   2  52   2   4   3]\n",
      " [ 11   2   1   7  48   3   4]\n",
      " [  7   0   1   2   2  70   0]\n",
      " [  7   3   3   3   7   3  38]]\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9221 - accuracy: 0.2343\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8405 - accuracy: 0.3035\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7572 - accuracy: 0.3026\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6353 - accuracy: 0.3072\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.4800 - accuracy: 0.4105\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2453 - accuracy: 0.5480\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9842 - accuracy: 0.6734\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7590 - accuracy: 0.7472\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.8303\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8745\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.9207\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9437\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9622\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9705\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9769\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9760\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9815\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9899\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9871\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9908\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9963\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9908\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9972\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9954\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9954\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9963\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9982\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9991\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9972\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9945\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9972\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9972\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9991\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9991\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9963\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9982\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9954\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9982\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9991\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9982\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9991\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 0.9982\n",
      "Score for fold 2: loss of 1.9082883596420288; accuracy of 68.2070255279541%\n",
      "Accuracy: 0.6820702402957486\n",
      "f1: 0.6483767586494722\n",
      "confusion matrix:\n",
      " [[135   2   4  12  10   5   3]\n",
      " [  5  19   1   3   3   4   8]\n",
      " [  9   1  27   1   2   5   1]\n",
      " [ 16   0   1  43   3   0   7]\n",
      " [ 11   3   1   7  34   3   9]\n",
      " [  9   3   5   0   2  62   1]\n",
      " [  3   2   1   2   4   0  49]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "loss_function = sparse_categorical_crossentropy\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "models=[]\n",
    "fold_no=0\n",
    "\n",
    "#train_x=full_train_x\n",
    "#train_y=full_train_y\n",
    "#hot_train_y=hot_full_train_y\n",
    "\n",
    "for train, test in kfold.split(train_x, hot_train_y):\n",
    "   \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=len(train_x[0]), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    history = model.fit(train_x[train], train_y[train],\n",
    "              batch_size=100,\n",
    "              epochs=50,\n",
    "             )\n",
    "    scores = model.evaluate(train_x[test], train_y[test], verbose=0)\n",
    "    models.append(model)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    pred=model.predict(train_x[test])\n",
    "    y_pred=convert_from_one_hot(pred)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score( train_y[test], y_pred))\n",
    "    print(\"f1:\",metrics.f1_score( train_y[test], y_pred,average='macro'))\n",
    "    print(\"confusion matrix:\\n\",metrics.confusion_matrix(train_y[test], y_pred))\n",
    "    \n",
    "    \n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.4687252044677734 - Accuracy: 74.16974306106567%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.9200348854064941 - Accuracy: 70.47970294952393%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.9082883596420288 - Accuracy: 68.2070255279541%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 70.95215717951457 (+- 2.4570863293063288)\n",
      "> Loss: 1.7656828165054321\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------fold number 0------\n",
      "Accuracy: 0.7183748845798708\n",
      "f1: 0.6953561374768409\n",
      "confusion matrix:\n",
      " [[254   1   9  15  17  12  11]\n",
      " [  9  35   1   1   7   1   9]\n",
      " [ 10   1  60   9   4   7   5]\n",
      " [ 37   1   2 139   6   3   5]\n",
      " [ 29   6   1   7  79   5  12]\n",
      " [ 11   0   7   0   2 136   5]\n",
      " [ 11   5   1   7   7   6  75]]\n",
      "-------fold number 1------\n",
      "Accuracy: 0.7386888273314867\n",
      "f1: 0.7124931988298286\n",
      "confusion matrix:\n",
      " [[266   2   4  27  10   5   5]\n",
      " [ 13  32   0   1  11   2   4]\n",
      " [ 13   0  68   3   1   7   4]\n",
      " [ 32   4   3 145   5   2   2]\n",
      " [ 31   7   1  10  79   3   8]\n",
      " [ 11   1   3   1   2 137   6]\n",
      " [ 10   6   2   3   9   9  73]]\n",
      "-------fold number 2------\n",
      "Accuracy: 0.7386888273314867\n",
      "f1: 0.7122533527952767\n",
      "confusion matrix:\n",
      " [[265   1   6  18  14   9   6]\n",
      " [  3  35   2   4  11   3   5]\n",
      " [ 12   0  63   3   5   6   7]\n",
      " [ 31   4   1 146   6   3   2]\n",
      " [ 21   5   6   6  81   7  13]\n",
      " [ 16   1   5   1   3 131   4]\n",
      " [  7   2   2   4  10   8  79]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model,fold in zip(models,range(0,len(models))):\n",
    "    print(f'-------fold number {fold}------')\n",
    "    pred=model.predict(test_x)\n",
    "    y_pred=convert_from_one_hot(pred)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "    print(\"f1:\",metrics.f1_score(test_y, y_pred,average='macro'))\n",
    "    print(\"confusion matrix:\\n\",metrics.confusion_matrix(test_y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b1ab523bc40703e7c4f09cc002dd307caa8b861633741d7ebd49339b733c3d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tesiNew': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
